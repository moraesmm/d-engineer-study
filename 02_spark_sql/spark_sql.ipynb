{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL - Queries SQL no Spark\n",
    "\n",
    "Este notebook cobre:\n",
    "- Views temporárias\n",
    "- Queries SQL básicas e avançadas\n",
    "- CTEs (Common Table Expressions)\n",
    "- Window Functions em SQL\n",
    "- Subqueries e correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQL_Estudo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Criando Dados e Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de exemplo\n",
    "funcionarios_data = [\n",
    "    (1, \"João\", \"Vendas\", 5000.0, \"2023-01-15\", 1),\n",
    "    (2, \"Maria\", \"TI\", 7500.0, \"2022-06-20\", 2),\n",
    "    (3, \"Pedro\", \"Vendas\", 4500.0, \"2023-03-10\", 1),\n",
    "    (4, \"Ana\", \"RH\", 6000.0, \"2021-11-05\", 3),\n",
    "    (5, \"Carlos\", \"TI\", 8000.0, \"2020-08-22\", 2),\n",
    "    (6, \"Julia\", \"TI\", 6500.0, \"2023-07-01\", 2),\n",
    "]\n",
    "\n",
    "vendas_data = [\n",
    "    (1, 1, 10000.0, \"2024-01-15\"),\n",
    "    (2, 1, 15000.0, \"2024-02-20\"),\n",
    "    (3, 3, 8000.0, \"2024-01-25\"),\n",
    "    (4, 1, 12000.0, \"2024-03-10\"),\n",
    "    (5, 3, 9500.0, \"2024-02-28\"),\n",
    "]\n",
    "\n",
    "departamentos_data = [\n",
    "    (1, \"Vendas\", \"São Paulo\"),\n",
    "    (2, \"TI\", \"Rio de Janeiro\"),\n",
    "    (3, \"RH\", \"Belo Horizonte\"),\n",
    "]\n",
    "\n",
    "df_funcionarios = spark.createDataFrame(\n",
    "    funcionarios_data,\n",
    "    [\"id\", \"nome\", \"departamento\", \"salario\", \"data_contratacao\", \"dept_id\"]\n",
    ")\n",
    "\n",
    "df_vendas = spark.createDataFrame(\n",
    "    vendas_data,\n",
    "    [\"venda_id\", \"funcionario_id\", \"valor\", \"data_venda\"]\n",
    ")\n",
    "\n",
    "df_departamentos = spark.createDataFrame(\n",
    "    departamentos_data,\n",
    "    [\"dept_id\", \"nome_dept\", \"cidade\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registrando views temporárias\n",
    "df_funcionarios.createOrReplaceTempView(\"funcionarios\")\n",
    "df_vendas.createOrReplaceTempView(\"vendas\")\n",
    "df_departamentos.createOrReplaceTempView(\"departamentos\")\n",
    "\n",
    "# View global (visível em todas as sessões)\n",
    "# df_funcionarios.createOrReplaceGlobalTempView(\"funcionarios_global\")\n",
    "# Acesso: SELECT * FROM global_temp.funcionarios_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Queries Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT simples\n",
    "spark.sql(\"SELECT * FROM funcionarios\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT com filtro e ordenação\n",
    "spark.sql(\"\"\"\n",
    "    SELECT nome, salario, departamento\n",
    "    FROM funcionarios\n",
    "    WHERE salario > 5000\n",
    "    ORDER BY salario DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT com funções\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        nome,\n",
    "        salario,\n",
    "        salario * 12 AS salario_anual,\n",
    "        UPPER(nome) AS nome_maiusculo,\n",
    "        YEAR(data_contratacao) AS ano_contratacao\n",
    "    FROM funcionarios\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agregações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        departamento,\n",
    "        COUNT(*) AS total_funcionarios,\n",
    "        SUM(salario) AS soma_salarios,\n",
    "        AVG(salario) AS media_salario,\n",
    "        MIN(salario) AS menor_salario,\n",
    "        MAX(salario) AS maior_salario,\n",
    "        ROUND(STDDEV(salario), 2) AS desvio_padrao\n",
    "    FROM funcionarios\n",
    "    GROUP BY departamento\n",
    "    HAVING COUNT(*) > 1\n",
    "    ORDER BY media_salario DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner Join\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        f.nome,\n",
    "        f.salario,\n",
    "        d.nome_dept,\n",
    "        d.cidade\n",
    "    FROM funcionarios f\n",
    "    INNER JOIN departamentos d ON f.dept_id = d.dept_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join com vendas e agregação\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        f.nome,\n",
    "        f.departamento,\n",
    "        COALESCE(SUM(v.valor), 0) AS total_vendas,\n",
    "        COUNT(v.venda_id) AS qtd_vendas\n",
    "    FROM funcionarios f\n",
    "    LEFT JOIN vendas v ON f.id = v.funcionario_id\n",
    "    GROUP BY f.nome, f.departamento\n",
    "    ORDER BY total_vendas DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Subqueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subquery no WHERE\n",
    "spark.sql(\"\"\"\n",
    "    SELECT nome, salario\n",
    "    FROM funcionarios\n",
    "    WHERE salario > (SELECT AVG(salario) FROM funcionarios)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subquery correlacionada - maior salário por departamento\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        f1.nome,\n",
    "        f1.departamento,\n",
    "        f1.salario\n",
    "    FROM funcionarios f1\n",
    "    WHERE f1.salario = (\n",
    "        SELECT MAX(f2.salario)\n",
    "        FROM funcionarios f2\n",
    "        WHERE f2.departamento = f1.departamento\n",
    "    )\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CTEs (Common Table Expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH stats_dept AS (\n",
    "        SELECT\n",
    "            departamento,\n",
    "            AVG(salario) AS media_salario,\n",
    "            COUNT(*) AS total_func\n",
    "        FROM funcionarios\n",
    "        GROUP BY departamento\n",
    "    ),\n",
    "    vendedores_ativos AS (\n",
    "        SELECT DISTINCT funcionario_id\n",
    "        FROM vendas\n",
    "        WHERE data_venda >= '2024-01-01'\n",
    "    )\n",
    "    SELECT\n",
    "        f.nome,\n",
    "        f.departamento,\n",
    "        f.salario,\n",
    "        sd.media_salario AS media_dept,\n",
    "        CASE \n",
    "            WHEN va.funcionario_id IS NOT NULL THEN 'Sim' \n",
    "            ELSE 'Não' \n",
    "        END AS vendeu_2024\n",
    "    FROM funcionarios f\n",
    "    JOIN stats_dept sd ON f.departamento = sd.departamento\n",
    "    LEFT JOIN vendedores_ativos va ON f.id = va.funcionario_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Window Functions em SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        nome,\n",
    "        departamento,\n",
    "        salario,\n",
    "        ROW_NUMBER() OVER (PARTITION BY departamento ORDER BY salario DESC) AS row_num,\n",
    "        RANK() OVER (PARTITION BY departamento ORDER BY salario DESC) AS ranking,\n",
    "        DENSE_RANK() OVER (PARTITION BY departamento ORDER BY salario DESC) AS dense_ranking,\n",
    "        SUM(salario) OVER (PARTITION BY departamento) AS total_dept,\n",
    "        AVG(salario) OVER (PARTITION BY departamento) AS media_dept\n",
    "    FROM funcionarios\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead, Lag e outros\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        nome,\n",
    "        salario,\n",
    "        LEAD(salario, 1) OVER (ORDER BY salario) AS proximo_salario,\n",
    "        LAG(salario, 1) OVER (ORDER BY salario) AS salario_anterior,\n",
    "        FIRST_VALUE(nome) OVER (PARTITION BY departamento ORDER BY salario DESC) AS top_salario_nome,\n",
    "        NTILE(4) OVER (ORDER BY salario) AS quartil\n",
    "    FROM funcionarios\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running total (soma acumulada)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        v.data_venda,\n",
    "        v.valor,\n",
    "        SUM(v.valor) OVER (\n",
    "            ORDER BY v.data_venda \n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS running_total\n",
    "    FROM vendas v\n",
    "    ORDER BY v.data_venda\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CASE WHEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        nome,\n",
    "        salario,\n",
    "        CASE\n",
    "            WHEN salario < 5000 THEN 'Junior'\n",
    "            WHEN salario BETWEEN 5000 AND 7000 THEN 'Pleno'\n",
    "            ELSE 'Senior'\n",
    "        END AS nivel,\n",
    "        CASE departamento\n",
    "            WHEN 'TI' THEN 'Tecnologia'\n",
    "            WHEN 'RH' THEN 'Recursos Humanos'\n",
    "            ELSE departamento\n",
    "        END AS dept_completo\n",
    "    FROM funcionarios\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Funções de Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        nome,\n",
    "        data_contratacao,\n",
    "        YEAR(data_contratacao) AS ano,\n",
    "        MONTH(data_contratacao) AS mes,\n",
    "        DAY(data_contratacao) AS dia,\n",
    "        QUARTER(data_contratacao) AS trimestre,\n",
    "        DATE_FORMAT(data_contratacao, 'dd/MM/yyyy') AS data_br,\n",
    "        DATEDIFF(CURRENT_DATE(), data_contratacao) AS dias_empresa,\n",
    "        ADD_MONTHS(data_contratacao, 12) AS um_ano_depois,\n",
    "        LAST_DAY(data_contratacao) AS ultimo_dia_mes\n",
    "    FROM funcionarios\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Funções de String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        nome,\n",
    "        UPPER(nome) AS maiusculo,\n",
    "        LOWER(nome) AS minusculo,\n",
    "        LENGTH(nome) AS tamanho,\n",
    "        CONCAT(nome, ' - ', departamento) AS nome_dept,\n",
    "        SUBSTRING(nome, 1, 3) AS primeiras_letras,\n",
    "        REPLACE(departamento, 'Vendas', 'Sales') AS dept_en,\n",
    "        LPAD(CAST(id AS STRING), 5, '0') AS id_formatado\n",
    "    FROM funcionarios\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. EXISTS, IN, UNION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXISTS - funcionários que têm vendas\n",
    "spark.sql(\"\"\"\n",
    "    SELECT f.nome, f.departamento\n",
    "    FROM funcionarios f\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1 FROM vendas v WHERE v.funcionario_id = f.id\n",
    "    )\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT EXISTS - funcionários sem vendas\n",
    "spark.sql(\"\"\"\n",
    "    SELECT f.nome, f.departamento\n",
    "    FROM funcionarios f\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM vendas v WHERE v.funcionario_id = f.id\n",
    "    )\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNION\n",
    "spark.sql(\"\"\"\n",
    "    SELECT nome, departamento FROM funcionarios WHERE departamento = 'TI'\n",
    "    UNION ALL\n",
    "    SELECT nome, departamento FROM funcionarios WHERE salario > 6000\n",
    "\"\"\").show()\n",
    "\n",
    "# INTERSECT\n",
    "spark.sql(\"\"\"\n",
    "    SELECT nome FROM funcionarios WHERE departamento = 'TI'\n",
    "    INTERSECT\n",
    "    SELECT nome FROM funcionarios WHERE salario > 6000\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Explain - Analisando Plano de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT f.nome, SUM(v.valor) as total\n",
    "    FROM funcionarios f\n",
    "    JOIN vendas v ON f.id = v.funcionario_id\n",
    "    GROUP BY f.nome\n",
    "\"\"\").explain(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
